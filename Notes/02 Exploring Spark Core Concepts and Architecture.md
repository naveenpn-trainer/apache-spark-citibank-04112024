# Exploring Spark Core Concepts and Architecture

> Apache Spark is an **in-memory cluster computing framework** designed to handle a wide range of big data workloads

1. Data Integration and ETL
2. High Performance Batch Computation
3. Stream Processing
4. Machine Learning Analytics
5. Graph Computation

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeckNGzILxPHxvTgnp9z8Csyc38rVYl_fEZdqW4Y7Hiz6Lg-m83P7jrHRjGVM0DQ9bs5f-zRAIpPbc-CsDIFw5N9ar1H3kP2BXLRn9qr3SpCUKoMl4IIAygMqDa3Ikzn2IVGy3nqOCRCnV4hY0QXDU4ySpH?key=Lcjgu0sLjm8U8i3A_14gRg)

* Apache Spark is natively written using Scala (Programming Language)

## What is PySpark

> PySpark is a Python API for Apache Spark (Distributed Processing Framework)

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeiopwx-CJrn019uT7IkesvLdD0bns61McbsY7fuVHneB-VFhEbfTZI5VNno_N5l4RXMNTd-rIlwZHZPGeSWXMC96JOytsJGXvM7-RwX5RCxH_8BmfKQ5nG32km7j9lIBMX22NhlNhZ2zgPYhNtVeI4euE?key=uvmlVet7-pBAx-jz0PuzLA)

## Spark Ecosystem

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeGEX3VP97EyLN2tB7QdhleO0gQRPs6GA74Nd-yWgpuoXp3p4LFMj-dMVdnYW94Y-2QHz3dhSNbK7Fy6hgc-fbmJrzYpjNtuvcLYuOKwrdFl2cEkBk8VIo7ky9xAJJoqij-SUUtiP38EEccTS0jhMUr6-w?key=uvmlVet7-pBAx-jz0PuzLA)

## Spark Interactive Shell

1. SparkShell
2. PySpark



































